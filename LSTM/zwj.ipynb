{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim学习：\n",
    "https://zhuanlan.zhihu.com/p/37175253\n",
    "https://blog.csdn.net/sinat_26917383/article/details/69803018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import jieba\n",
    "from gensim.models import KeyedVectors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('embeddings/sgns.zhihu.bigram','wb') as new_file,open('embeddings/sgns.zhihu.bigram.bz2','rb') as file:\n",
    "#     decompressor=bz2.BZ2Decompressor()\n",
    "#     for data in iter(lambda:file.read(100*1024),b''):\n",
    "#         new_file.write(decompressor.decompress(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_model=KeyedVectors.load_word2vec_format('embeddings/sgns.zhihu.bigram',binary=False,unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim=cn_model['山东大学'].shape[0]\n",
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66128117"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_model.similarity('橘子','橙子')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66128117"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(cn_model['橘子']/np.linalg.norm(cn_model['橘子']),cn_model['橙子']/np.linalg.norm(cn_model['橙子']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('圣女果', 0.6986043453216553),\n",
       " ('火龙果', 0.6928063631057739),\n",
       " ('哈密瓜', 0.6855860948562622),\n",
       " ('山竹', 0.6833729147911072),\n",
       " ('油桃', 0.682028591632843),\n",
       " ('卷心菜', 0.6734050512313843),\n",
       " ('板栗', 0.6704466938972473),\n",
       " ('百香果', 0.6689621806144714),\n",
       " ('梨子', 0.6672431230545044),\n",
       " ('桃子', 0.6646143794059753)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_model.most_similar(positive=['橘子'],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('火龙果', 0.7393988370895386),\n",
       " ('哈密瓜', 0.7348312139511108),\n",
       " ('桃子', 0.7337439060211182),\n",
       " ('圣女果', 0.7326869368553162),\n",
       " ('柚子', 0.7324603796005249),\n",
       " ('山竹', 0.7232064008712769),\n",
       " ('梨子', 0.722402811050415),\n",
       " ('油桃', 0.7187268733978271),\n",
       " ('卷心菜', 0.7105546593666077),\n",
       " ('金桔', 0.7091059684753418)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_model.most_similar(positive=['橘子','橙子'],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# pos_txts=os.listdir('pos')\n",
    "# neg_txts=os.listdir('neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总量：4000\n"
     ]
    }
   ],
   "source": [
    "# print('样本总量：{}'.format(len(pos_txts)+len(neg_txts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_orig=[]\n",
    "train_target=[]\n",
    "with open('positive_samples.txt','r',encoding='utf-8') as f:\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        dic=eval(line)\n",
    "        train_texts_orig.append(dic['text'])\n",
    "        train_target.append(dic['label'])\n",
    "\n",
    "with open('negative_samples.txt','r',encoding='utf-8') as f:\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        dic=eval(line)\n",
    "        train_texts_orig.append(dic['text'])\n",
    "        train_target.append(dic['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_texts_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,GRU,Embedding,LSTM,Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping,ModelCheckpoint,TensorBoard,ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens=[]\n",
    "for text in train_texts_orig:\n",
    "    text=re.sub('[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+','',text)\n",
    "    cut=jieba.cut(text)\n",
    "    cut_list=[i for i in cut]\n",
    "    for i,word in enumerate(cut_list):\n",
    "        try:\n",
    "            cut_list[i]=cn_model.vocab[word].index\n",
    "        except KeyError:\n",
    "            cut_list[i]=0\n",
    "    train_tokens.append(cut_list)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4656,\n",
       " 163,\n",
       " 710,\n",
       " 909,\n",
       " 32,\n",
       " 328,\n",
       " 12,\n",
       " 1899,\n",
       " 18,\n",
       " 8685,\n",
       " 1604,\n",
       " 1,\n",
       " 1845,\n",
       " 144,\n",
       " 2420,\n",
       " 153,\n",
       " 36,\n",
       " 75,\n",
       " 3,\n",
       " 1487,\n",
       " 571,\n",
       " 34,\n",
       " 72]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#获取每行 分词的个数\n",
    "num_tokens=[len(tokens) for tokens in train_tokens]\n",
    "num_tokens=np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.4495"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1540"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log(num_tokens),bins=100)\n",
    "plt.xlim(0,10)\n",
    "plt.ylabel('number of tokens')\n",
    "plt.xlabel('length of tokens')\n",
    "plt.title('Distribution of token length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens=np.mean(num_tokens)+2*np.std(num_tokens)\n",
    "max_tokens=int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9565"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens<max_tokens)/len(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_tokens(tokens):\n",
    "    text=''\n",
    "    for i in tokens:\n",
    "        if i != 0:\n",
    "            text=text+cn_model.index2word[i]\n",
    "        else:\n",
    "            text=text+' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CBD中心周围没什么店铺说5星有点勉强不知道为什么卫生间没有电吹风'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse=reverse_tokens(train_tokens[2])\n",
    "reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts_orig[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#只取字典表里使用频率最高的前50000个词的embedding,其它词按‘空格’处理\n",
    "num_words=50000\n",
    "embedding_matrix=np.zeros((num_words,embedding_dim))\n",
    "for i in range(num_words):\n",
    "    embedding_matrix[i,:]=cn_model[cn_model.index2word[i]]\n",
    "embedding_matrix=embedding_matrix.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(cn_model[cn_model.index2word[333]]==embedding_matrix[333])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 300)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pad=pad_sequences(train_tokens,maxlen=max_tokens,padding='pre',truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pad[train_pad>=num_words]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tokens[33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236,)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pad[33].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target=np.array(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(train_pad,train_target,test_size=0.1,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                        房间很大还有海景阳台走出酒店就是沙滩非常不错唯一遗憾的就是不能刷 不方便\n",
      "class: 1\n"
     ]
    }
   ],
   "source": [
    "print(reverse_tokens(X_train[35]))\n",
    "print('class:',y_train[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(num_words,embedding_dim,weights=[embedding_matrix],input_length=max_tokens,trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Bidirectional(LSTM(units=64,return_sequences=True)))\n",
    "model.add(LSTM(units=16,return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1,activation='sigmoid'))\n",
    "optimizer=Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 236, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 236, 128)          186880    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                9280      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,196,177\n",
      "Trainable params: 196,177\n",
      "Non-trainable params: 15,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint='sentiment_checkpoint.keras'\n",
    "checkpoint=ModelCheckpoint(filepath=path_checkpoint,monitor='val_loss',verbose=1,save_weights_only=True,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to open file (unable to open file: name = 'sentiment_checkpoint.keras', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.load_weights(path_checkpoint)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping=EarlyStopping(monitor='val_loss',patience=5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reduction=ReduceLROnPlateau(monitor='val_loss',factor=0.1,min_lr=1e-8,patience=0,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[earlystopping,checkpoint,lr_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3240 samples, validate on 360 samples\n",
      "Epoch 1/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2992 - accuracy: 0.8806\n",
      "Epoch 00001: val_loss improved from 0.33192 to 0.33192, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 2/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2977 - accuracy: 0.8813\n",
      "Epoch 00002: val_loss improved from 0.33192 to 0.33192, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 3/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2994 - accuracy: 0.8803\n",
      "Epoch 00003: val_loss improved from 0.33192 to 0.33192, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 4/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2993 - accuracy: 0.8803\n",
      "Epoch 00004: val_loss improved from 0.33192 to 0.33192, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 35s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 5/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2977 - accuracy: 0.8813\n",
      "Epoch 00005: val_loss improved from 0.33192 to 0.33192, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 35s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 6/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2993 - accuracy: 0.8806\n",
      "Epoch 00006: val_loss improved from 0.33192 to 0.33192, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 35s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 7/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2996 - accuracy: 0.8803\n",
      "Epoch 00007: val_loss did not improve from 0.33192\n",
      "3240/3240 [==============================] - 35s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 8/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2988 - accuracy: 0.8806\n",
      "Epoch 00008: val_loss improved from 0.33192 to 0.33191, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 35s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 9/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3003 - accuracy: 0.8797\n",
      "Epoch 00009: val_loss improved from 0.33191 to 0.33191, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 35s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 10/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2997 - accuracy: 0.8806\n",
      "Epoch 00010: val_loss improved from 0.33191 to 0.33191, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 11/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2989 - accuracy: 0.8809\n",
      "Epoch 00011: val_loss improved from 0.33191 to 0.33191, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 12/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3001 - accuracy: 0.8803\n",
      "Epoch 00012: val_loss improved from 0.33191 to 0.33191, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 13/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2999 - accuracy: 0.8800\n",
      "Epoch 00013: val_loss improved from 0.33191 to 0.33191, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 14/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3007 - accuracy: 0.8794\n",
      "Epoch 00014: val_loss improved from 0.33191 to 0.33191, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 15/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2980 - accuracy: 0.8809\n",
      "Epoch 00015: val_loss improved from 0.33191 to 0.33190, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 35s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 16/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2979 - accuracy: 0.8816\n",
      "Epoch 00016: val_loss improved from 0.33190 to 0.33190, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 35s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 17/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2986 - accuracy: 0.8809\n",
      "Epoch 00017: val_loss improved from 0.33190 to 0.33190, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 18/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2990 - accuracy: 0.8809\n",
      "Epoch 00018: val_loss improved from 0.33190 to 0.33190, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8583\n",
      "Epoch 19/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2985 - accuracy: 0.8809\n",
      "Epoch 00019: val_loss improved from 0.33190 to 0.33190, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 35s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 20/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2982 - accuracy: 0.8816\n",
      "Epoch 00020: val_loss improved from 0.33190 to 0.33190, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 21/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2996 - accuracy: 0.8803\n",
      "Epoch 00021: val_loss improved from 0.33190 to 0.33190, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 22/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2994 - accuracy: 0.8809\n",
      "Epoch 00022: val_loss improved from 0.33190 to 0.33190, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 23/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2985 - accuracy: 0.8813\n",
      "Epoch 00023: val_loss improved from 0.33190 to 0.33189, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 35s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 24/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2987 - accuracy: 0.8813\n",
      "Epoch 00024: val_loss improved from 0.33189 to 0.33189, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 25/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2974 - accuracy: 0.8822\n",
      "Epoch 00025: val_loss did not improve from 0.33189\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3003 - accuracy: 0.8803\n",
      "Epoch 00026: val_loss improved from 0.33189 to 0.33189, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 27/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.8803\n",
      "Epoch 00027: val_loss improved from 0.33189 to 0.33189, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 28/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2977 - accuracy: 0.8819\n",
      "Epoch 00028: val_loss improved from 0.33189 to 0.33189, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 29/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3006 - accuracy: 0.8803\n",
      "Epoch 00029: val_loss improved from 0.33189 to 0.33189, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 12ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 30/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2996 - accuracy: 0.8803\n",
      "Epoch 00030: val_loss improved from 0.33189 to 0.33188, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 31/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2996 - accuracy: 0.8806\n",
      "Epoch 00031: val_loss improved from 0.33188 to 0.33188, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 32/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2977 - accuracy: 0.8813\n",
      "Epoch 00032: val_loss improved from 0.33188 to 0.33188, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 33/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2998 - accuracy: 0.8800\n",
      "Epoch 00033: val_loss improved from 0.33188 to 0.33188, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 34/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3009 - accuracy: 0.8797\n",
      "Epoch 00034: val_loss improved from 0.33188 to 0.33188, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 35/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2992 - accuracy: 0.8806\n",
      "Epoch 00035: val_loss improved from 0.33188 to 0.33188, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 36/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2999 - accuracy: 0.8800\n",
      "Epoch 00036: val_loss improved from 0.33188 to 0.33187, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 37/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.8800\n",
      "Epoch 00037: val_loss improved from 0.33187 to 0.33187, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 38/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.8797\n",
      "Epoch 00038: val_loss improved from 0.33187 to 0.33187, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 35s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 39/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.8806\n",
      "Epoch 00039: val_loss improved from 0.33187 to 0.33187, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 40/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2978 - accuracy: 0.8819\n",
      "Epoch 00040: val_loss improved from 0.33187 to 0.33187, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 41/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3002 - accuracy: 0.8803\n",
      "Epoch 00041: val_loss improved from 0.33187 to 0.33187, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 42/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2988 - accuracy: 0.8813\n",
      "Epoch 00042: val_loss improved from 0.33187 to 0.33186, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 43/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2990 - accuracy: 0.8809\n",
      "Epoch 00043: val_loss improved from 0.33186 to 0.33186, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 44/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3006 - accuracy: 0.8797\n",
      "Epoch 00044: val_loss improved from 0.33186 to 0.33186, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 45/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3000 - accuracy: 0.8803\n",
      "Epoch 00045: val_loss improved from 0.33186 to 0.33186, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 46/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3001 - accuracy: 0.8809\n",
      "Epoch 00046: val_loss improved from 0.33186 to 0.33186, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 47/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3014 - accuracy: 0.8794\n",
      "Epoch 00047: val_loss improved from 0.33186 to 0.33186, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 48/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2991 - accuracy: 0.8806\n",
      "Epoch 00048: val_loss improved from 0.33186 to 0.33186, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 49/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2984 - accuracy: 0.8806\n",
      "Epoch 00049: val_loss improved from 0.33186 to 0.33185, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 50/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3011 - accuracy: 0.8797\n",
      "Epoch 00050: val_loss improved from 0.33185 to 0.33185, saving model to sentiment_checkpoint.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 51/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.8797\n",
      "Epoch 00051: val_loss improved from 0.33185 to 0.33185, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3319 - val_accuracy: 0.8611\n",
      "Epoch 52/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2977 - accuracy: 0.8816\n",
      "Epoch 00052: val_loss improved from 0.33185 to 0.33185, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 35s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 53/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2967 - accuracy: 0.8822\n",
      "Epoch 00053: val_loss improved from 0.33185 to 0.33185, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 54/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3001 - accuracy: 0.8809\n",
      "Epoch 00054: val_loss improved from 0.33185 to 0.33185, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 55/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3002 - accuracy: 0.8803\n",
      "Epoch 00055: val_loss improved from 0.33185 to 0.33184, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 56/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3000 - accuracy: 0.8800\n",
      "Epoch 00056: val_loss improved from 0.33184 to 0.33184, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 57/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2997 - accuracy: 0.8806\n",
      "Epoch 00057: val_loss improved from 0.33184 to 0.33184, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 58/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2983 - accuracy: 0.8813\n",
      "Epoch 00058: val_loss improved from 0.33184 to 0.33184, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 59/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3000 - accuracy: 0.8800\n",
      "Epoch 00059: val_loss improved from 0.33184 to 0.33184, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 60/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2983 - accuracy: 0.8809\n",
      "Epoch 00060: val_loss improved from 0.33184 to 0.33184, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 61/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3001 - accuracy: 0.8800\n",
      "Epoch 00061: val_loss improved from 0.33184 to 0.33184, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 62/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3003 - accuracy: 0.8803\n",
      "Epoch 00062: val_loss improved from 0.33184 to 0.33183, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 63/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2974 - accuracy: 0.8816\n",
      "Epoch 00063: val_loss improved from 0.33183 to 0.33183, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 64/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2990 - accuracy: 0.8806\n",
      "Epoch 00064: val_loss improved from 0.33183 to 0.33183, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 65/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3002 - accuracy: 0.8800\n",
      "Epoch 00065: val_loss improved from 0.33183 to 0.33183, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 66/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2995 - accuracy: 0.8803\n",
      "Epoch 00066: val_loss improved from 0.33183 to 0.33183, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 67/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3009 - accuracy: 0.8797\n",
      "Epoch 00067: val_loss improved from 0.33183 to 0.33183, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 68/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2985 - accuracy: 0.8806\n",
      "Epoch 00068: val_loss improved from 0.33183 to 0.33183, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 36s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 69/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2994 - accuracy: 0.8800\n",
      "Epoch 00069: val_loss improved from 0.33183 to 0.33183, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 70/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3010 - accuracy: 0.8794\n",
      "Epoch 00070: val_loss improved from 0.33183 to 0.33182, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 71/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3000 - accuracy: 0.8803\n",
      "Epoch 00071: val_loss improved from 0.33182 to 0.33182, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 72/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3004 - accuracy: 0.8800\n",
      "Epoch 00072: val_loss improved from 0.33182 to 0.33182, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 73/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2994 - accuracy: 0.8803\n",
      "Epoch 00073: val_loss improved from 0.33182 to 0.33182, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 74/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2993 - accuracy: 0.8806\n",
      "Epoch 00074: val_loss improved from 0.33182 to 0.33182, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2987 - accuracy: 0.8809\n",
      "Epoch 00075: val_loss improved from 0.33182 to 0.33182, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 76/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3004 - accuracy: 0.8803\n",
      "Epoch 00076: val_loss improved from 0.33182 to 0.33181, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 77/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2988 - accuracy: 0.8809\n",
      "Epoch 00077: val_loss improved from 0.33181 to 0.33181, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 78/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2979 - accuracy: 0.8819\n",
      "Epoch 00078: val_loss improved from 0.33181 to 0.33181, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 79/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3008 - accuracy: 0.8797\n",
      "Epoch 00079: val_loss improved from 0.33181 to 0.33181, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 80/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2983 - accuracy: 0.8813\n",
      "Epoch 00080: val_loss improved from 0.33181 to 0.33181, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 81/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2999 - accuracy: 0.8797\n",
      "Epoch 00081: val_loss improved from 0.33181 to 0.33181, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 82/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2990 - accuracy: 0.8806\n",
      "Epoch 00082: val_loss improved from 0.33181 to 0.33181, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 83/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2988 - accuracy: 0.8809\n",
      "Epoch 00083: val_loss improved from 0.33181 to 0.33181, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 84/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2994 - accuracy: 0.8806\n",
      "Epoch 00084: val_loss improved from 0.33181 to 0.33180, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 37s 11ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 85/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3009 - accuracy: 0.8800\n",
      "Epoch 00085: val_loss improved from 0.33180 to 0.33180, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 86/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2981 - accuracy: 0.8809\n",
      "Epoch 00086: val_loss improved from 0.33180 to 0.33180, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 87/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3000 - accuracy: 0.8800\n",
      "Epoch 00087: val_loss improved from 0.33180 to 0.33180, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8806 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 88/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2985 - accuracy: 0.8809\n",
      "Epoch 00088: val_loss improved from 0.33180 to 0.33180, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 39s 12ms/sample - loss: 0.2993 - accuracy: 0.8802 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 89/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3017 - accuracy: 0.8788\n",
      "Epoch 00089: val_loss improved from 0.33180 to 0.33179, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 39s 12ms/sample - loss: 0.2993 - accuracy: 0.8802 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 90/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2986 - accuracy: 0.8806\n",
      "Epoch 00090: val_loss improved from 0.33179 to 0.33179, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 40s 12ms/sample - loss: 0.2993 - accuracy: 0.8802 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 91/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2999 - accuracy: 0.8800\n",
      "Epoch 00091: val_loss improved from 0.33179 to 0.33179, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 39s 12ms/sample - loss: 0.2993 - accuracy: 0.8802 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 92/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2999 - accuracy: 0.8797\n",
      "Epoch 00092: val_loss improved from 0.33179 to 0.33179, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8802 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 93/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3003 - accuracy: 0.8797\n",
      "Epoch 00093: val_loss improved from 0.33179 to 0.33179, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8802 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 94/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2985 - accuracy: 0.8816\n",
      "Epoch 00094: val_loss improved from 0.33179 to 0.33179, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8802 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 95/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2997 - accuracy: 0.8800\n",
      "Epoch 00095: val_loss improved from 0.33179 to 0.33178, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8802 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 96/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3001 - accuracy: 0.8797\n",
      "Epoch 00096: val_loss improved from 0.33178 to 0.33178, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8802 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 97/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3000 - accuracy: 0.8803\n",
      "Epoch 00097: val_loss improved from 0.33178 to 0.33178, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8802 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 98/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2998 - accuracy: 0.8797\n",
      "Epoch 00098: val_loss improved from 0.33178 to 0.33178, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8799 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 99/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3000 - accuracy: 0.8794\n",
      "Epoch 00099: val_loss improved from 0.33178 to 0.33178, saving model to sentiment_checkpoint.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8799 - val_loss: 0.3318 - val_accuracy: 0.8611\n",
      "Epoch 100/100\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2974 - accuracy: 0.8813\n",
      "Epoch 00100: val_loss improved from 0.33178 to 0.33178, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 38s 12ms/sample - loss: 0.2993 - accuracy: 0.8799 - val_loss: 0.3318 - val_accuracy: 0.8611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e070451780>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_split=0.1,epochs=100,batch_size=128,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "400/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 2s 4ms/sample - loss: 0.3450 - accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:84.00%\n"
     ]
    }
   ],
   "source": [
    "result=model.evaluate(X_test,y_test)\n",
    "print('Accuracy:{0:.2%}'.format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:84.00%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:{0:.2%}'.format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Vocab at 0x1e059104470>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_model.vocab['橘子']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('test.txt','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text=[]\n",
    "line=f.readline()\n",
    "while line:\n",
    "    text.append(line)\n",
    "    line=f.readline()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int(3.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pad_sequences in module keras_preprocessing.sequence:\n",
      "\n",
      "pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0)\n",
      "    Pads sequences to the same length.\n",
      "    \n",
      "    This function transforms a list of\n",
      "    `num_samples` sequences (lists of integers)\n",
      "    into a 2D Numpy array of shape `(num_samples, num_timesteps)`.\n",
      "    `num_timesteps` is either the `maxlen` argument if provided,\n",
      "    or the length of the longest sequence otherwise.\n",
      "    \n",
      "    Sequences that are shorter than `num_timesteps`\n",
      "    are padded with `value` at the end.\n",
      "    \n",
      "    Sequences longer than `num_timesteps` are truncated\n",
      "    so that they fit the desired length.\n",
      "    The position where padding or truncation happens is determined by\n",
      "    the arguments `padding` and `truncating`, respectively.\n",
      "    \n",
      "    Pre-padding is the default.\n",
      "    \n",
      "    # Arguments\n",
      "        sequences: List of lists, where each element is a sequence.\n",
      "        maxlen: Int, maximum length of all sequences.\n",
      "        dtype: Type of the output sequences.\n",
      "            To pad sequences with variable length strings, you can use `object`.\n",
      "        padding: String, 'pre' or 'post':\n",
      "            pad either before or after each sequence.\n",
      "        truncating: String, 'pre' or 'post':\n",
      "            remove values from sequences larger than\n",
      "            `maxlen`, either at the beginning or at the end of the sequences.\n",
      "        value: Float or String, padding value.\n",
      "    \n",
      "    # Returns\n",
      "        x: Numpy array with shape `(len(sequences), maxlen)`\n",
      "    \n",
      "    # Raises\n",
      "        ValueError: In case of invalid values for `truncating` or `padding`,\n",
      "            or in case of invalid shape for a `sequences` entry.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pad_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1669430916720"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=jieba.cut('这是一个测试')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I1223 20:21:45.334305  1928 __init__.py:111] Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "I1223 20:21:46.092200  1928 __init__.py:145] Dumping model to file cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.840 seconds.\n",
      "I1223 20:21:46.175977  1928 __init__.py:163] Loading model cost 0.840 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "I1223 20:21:46.176974  1928 __init__.py:164] Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是\n",
      "一个\n",
      "测试\n"
     ]
    }
   ],
   "source": [
    "for i in t:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 这是\n",
      "1 一个\n",
      "2 测试\n"
     ]
    }
   ],
   "source": [
    "for i,tt in enumerate(t):\n",
    "    print(i,tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack=[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
